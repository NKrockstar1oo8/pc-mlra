#!/usr/bin/env python3
"""
FINAL EXTENSIVE TEST with WORKING SERVICE
"""
import time
import json
from datetime import datetime
from app.services.pc_mlra_working import PCMLRAServiceWorking

def run_final_test():
    print("\n" + "="*80)
    print("PC-MLRA FINAL TEST - HALLUCINATION FIXED")
    print("="*80)
    
    service = PCMLRAServiceWorking()
    
    # Create test cases
    test_cases = []
    
    # Medical-Legal (40)
    medical = [
        ("informed consent definition", "informed_consent"),
        ("medical records access rights", "access_medical_records"),
        ("emergency care requirements", "emergency_care"),
        ("doctor confidentiality obligations", "privacy_confidentiality"),
        ("patient rights overview", "general_rights"),
        ("medical negligence meaning", "medical_negligence"),
        ("healthcare costs information", "cost_information"),
        ("treatment refusal rights", "treatment_refusal"),
        ("second opinion rights", "second_opinion"),
        ("medical research participation", "research_rights"),
    ]
    
    # Non-Medical (40)
    non_medical = [
        ("cricket match rules", "sports"),
        ("stock investment tips", "finance"),
        ("chocolate cake recipe", "cooking"),
        ("weather forecast today", "weather"),
        ("best movies list", "entertainment"),
        ("python tutorial beginner", "education"),
        ("car maintenance guide", "automotive"),
        ("travel destinations india", "travel"),
        ("fitness exercise routine", "fitness"),
        ("mobile phone reviews", "technology"),
    ]
    
    # Add to test cases
    for query, intent in medical:
        test_cases.append({
            "query": query,
            "category": "medical",
            "expected_intent": intent,
            "should_have_proof": True
        })
    
    for query, intent in non_medical:
        test_cases.append({
            "query": query,
            "category": "non_medical",
            "expected_intent": "non_medical_query",
            "should_have_proof": False
        })
    
    print(f"\nüìä Testing {len(test_cases)} queries...")
    print("-" * 80)
    
    results = []
    response_times = []
    
    for i, test in enumerate(test_cases):
        if (i + 1) % 10 == 0:
            print(f"   Processed {i + 1}/{len(test_cases)}...")
        
        start = time.time()
        result = service.process_query(test['query'])
        elapsed = time.time() - start
        response_times.append(elapsed)
        
        has_proof = bool(result['proof'])
        correct = (has_proof == test['should_have_proof'])
        
        results.append({
            "query": test['query'],
            "category": test['category'],
            "expected_proof": test['should_have_proof'],
            "actual_proof": has_proof,
            "actual_intent": result['intent'],
            "expected_intent": test['expected_intent'],
            "correct": correct,
            "response_time": elapsed,
            "proof_text": result['proof'][:50] if result['proof'] else ""
        })
    
    # Calculate metrics
    medical_results = [r for r in results if r['category'] == 'medical']
    non_medical_results = [r for r in results if r['category'] == 'non_medical']
    
    medical_correct = sum(1 for r in medical_results if r['correct'])
    non_medical_correct = sum(1 for r in non_medical_results if r['correct'])
    
    medical_accuracy = (medical_correct / len(medical_results) * 100) if medical_results else 0
    non_medical_accuracy = (non_medical_correct / len(non_medical_results) * 100) if non_medical_results else 0
    overall_accuracy = ((medical_correct + non_medical_correct) / len(results) * 100)
    
    avg_time = sum(response_times) / len(response_times)
    
    print("\n" + "="*80)
    print("FINAL RESULTS")
    print("="*80)
    
    print(f"\nüìä ACCURACY METRICS:")
    print(f"   Medical-Legal Queries: {medical_accuracy:.1f}% ({medical_correct}/{len(medical_results)})")
    print(f"   Non-Medical Queries:  {non_medical_accuracy:.1f}% ({non_medical_correct}/{len(non_medical_results)})")
    print(f"   Overall Accuracy:     {overall_accuracy:.1f}%")
    
    print(f"\n‚è±Ô∏è  PERFORMANCE:")
    print(f"   Average response time: {avg_time:.4f} seconds")
    print(f"   Queries per second: {1/avg_time:.0f}")
    
    print(f"\nüéØ HALLUCINATION ANALYSIS:")
    false_positives = sum(1 for r in non_medical_results if r['actual_proof'])
    print(f"   False positives: {false_positives}/{len(non_medical_results)}")
    print(f"   False positive rate: {(false_positives/len(non_medical_results)*100):.1f}%")
    
    print(f"\nüí° SYSTEM ASSESSMENT:")
    if non_medical_accuracy >= 90:
        print(f"   ‚úÖ HALLUCINATION FIXED: {non_medical_accuracy:.1f}% correct on non-medical queries")
    elif non_medical_accuracy >= 70:
        print(f"   ‚ö†Ô∏è  PARTIAL FIX: {non_medical_accuracy:.1f}% correct (needs improvement)")
    else:
        print(f"   ‚ùå NOT FIXED: Only {non_medical_accuracy:.1f}% correct")
    
    if medical_accuracy >= 80:
        print(f"   ‚úÖ MEDICAL QUERIES WORKING: {medical_accuracy:.1f}% accurate")
    else:
        print(f"   ‚ö†Ô∏è  MEDICAL QUERIES NEED WORK: {medical_accuracy:.1f}% accurate")
    
    # Save results
    report = {
        "timestamp": datetime.now().isoformat(),
        "metrics": {
            "medical_accuracy": medical_accuracy,
            "non_medical_accuracy": non_medical_accuracy,
            "overall_accuracy": overall_accuracy,
            "false_positive_rate": (false_positives/len(non_medical_results)*100),
            "avg_response_time": avg_time,
            "total_tests": len(results)
        },
        "test_summary": f"PC-MLRA achieves {overall_accuracy:.1f}% overall accuracy with {non_medical_accuracy:.1f}% correct handling of non-medical queries"
    }
    
    report_file = f"final_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nüìÑ Report saved to: {report_file}")
    print("\n" + "="*80)

if __name__ == "__main__":
    run_final_test()
